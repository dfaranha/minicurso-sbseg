\subsection{Níveis em que os ataques SCA podem ser aplicados}

\begin{comment}
\subsubsection{Operações na curva}
\subsubsection{Operações no protocolo criptográfico}
\subsubsection{Transferência da chave entre diferentes memórias}

\subsubsection{Protocolo em nível de aplicação}
\end{comment}

%TODO: Figura com piramide de ataques SCA.

%TODO 1 parag. p/ explicar a figura e discutir exemplos de ataques em cada nível.

%TODO: "Transferência da chave entre diferentes memórias"

%TODO: processamento da chave fora do algoritmo criptográfico.
% Ref. sobre um SCA bem sucedido deste tipo: Witteman, M. (2013). Secure Application Programming in the Presence of Side Channel Attacks.\cite{Witteman2013_PatternsAppsecSCA}
% Demonstra um ataque à verificação de paridade da chave na biblioteca GnuPG.

%TODO: Protocolo em nivel de aplicacao


\subsection{Ataques de tempo e SPA ao algoritmo double-and-add-not-always}

\subsubsection{Ataque de tempo ao algoritmo double-and-add-not-always}
\erick[inline]{Lucas: ver o comentario no fonte. Converter comentario em texto}.

\begin{comment}
1.	Ataque SPA à alg. ECSM binário left-to-right (Dbl-and-Add not Always)
	a.	Se impl não é de tempo constante, então é possível realizar ataque de tempo.
		i.	P.ex., se usa if and else, então pode-se determinar a cada iteração qual bloco, if ou else, é tomado.
	b. O ataque de tempo em~\cite{Kocher96} ao RSA pode ser aplicado no contexto de ECC. Segue abaixo a ideia do ataque (baseada no survey de ~\cite{Danger2013}, Sec. 3.2.1).
	
	O atacante coleta o tempo de execução de diferentes ECSMs com o mesmo escalar e diferentes pontos base. Para cada ECSM, ele simula a computação usando um simulador de software com exatamente a mesma implementação do chip alvo, "chutando" o valor do bit $i$ do escalar. Suponha, sem perda de generalidade, que a hipótese é de que o valor do bit é 0.  Ele separa os diferentes tempos de execução em dois conjuntos, S_1 e S_2. Se, a iteração
	
	%TODO: CONT HERE
	

[Kocher96] Kocher, P.C.: Timing attacks on implementations of Difﬁe–
Hellman, RSA, DSS, and other systems. In: Proceedings of CRYPTO’96, LNCS, vol. 1109. Springer, Berlin, pp. 104–113
(1996)
\end{comment}

\subsubsection{Ataque SPA ao algoritmo double-and-add-not-always}
\erick[inline]{Lucas: ver o comentario no fonte. Converter comentario em texto}.

\begin{comment}
b.	Se é de tempo constante, SPA (com ou sem power model) pode ser aplicado para distinguir os padrões no trace das iterações com apenas DBL (bit=0) daquelas com DBL+ADD (bit=1). Um ataque deste tipo segmenta/divide o trace de potencia de uma execucao do ECSM em subtraces, cada um contendo uma operacao de ponto (ADD ou DBL). Se as tempo(ADD) != tempo(DBL), então o comprimento dos subtraces revela onde estão os ADDs e consequentemente os bits do escalar. Se tempo(ADD) == tempo(DBL) e uma formula unificada para ADD and DBL é utilizada, então, se for aplicada correlação (coeficiente de correlacao de Pearson) entre todos os pares de subtraces, o resultado será que a correlação será mais alta para os pares de subtraces cuja operação correspondente é a mesma (i.e., (ADD,ADD) ou (DBL,DBL)), identificando portanto as operações de ponto e consequentemente os bits do escalar.
\end{comment}

%TODO 2. Argumentar que é fortemente desejável que as implementações sejam de tempo constante, de modo a ser uma base para a implementação das outra contramedidas para power analysis.

\subsection{Double-and-add-always algorithm of Coron~\cite{Coron1999}}

\erick[inline]{Lucas: traduzir esta secao}The {\it double-and-add-always} algorithm of Coron~\cite{Coron1999} (Algorithm~\ref{Double-and-add-Coron}) uses a dummy point addition when the scalar bit $k_i$ is $0$, such that the sequence of operations to compute the scalar multiplication is independent of the value of the secret scalar.

\begin{algorithm}[h] %\scriptsize %\footnotesize
	\caption{\small{\textit{Double-and-add always} algorithm resistant against SPA}}
	\label{Double-and-add-Coron}
	\begin{algorithmic}[1]
		\REQUIRE  Point $\textbf{P} \in E(\mathbb{F}_q),$ $k=(k_{n-1},\ldots,k_1,k_0)_2 \in \mathbb{N}$
		\ENSURE  $Q=[k] \cdot P$\\
		\STATE $R_0\leftarrow P_{\infty}$   \\
		\FOR{$i$ \textbf{from} $n-1$ \textbf{to} $0$} 
		\STATE $R_0\leftarrow 2R_0$  \\
		\STATE $R_1\leftarrow R_0+P$\\ \label{Paso_R_1_Double-and-add-Coron}
		\STATE $R_0\leftarrow R_{k_i}$\label{Step5Double-and-add-Coron} \\
		\ENDFOR
		\STATE return $R_0$\\
	\end{algorithmic}
\end{algorithm}

Therefore an adversary cannot, in principle, guess the value of bit $k_i$ by SPA. A drawback of this method is its low efficiency. It requires $nA+nD$ field operations, a $33\%$ increase in the amount of field operations in comparison to the (unprotected) binary left-to-right algorithm.

\subsubsection{Fouque and Valette's Doubling Attack \cite{CHES:FouVal03}}\label{Fouque-Valette-DoublingAttack}
The doubling attack of Fouque-Valette~\cite{CHES:FouVal03} is based on the fact that it is possible to detect if two intermediate values are equal when the algorithm computes the scalar multiplication for points chosen points $P$ and $2P.$ Several algorithms protected against SPA are vulnerable to Fouque and Valette's attack, such as the classic binary left-to-right algorithm, including those derived from it, such as Coron's double-and-add-always algorithm.

%In ~\textit{double-and-add-always} algorithm (Algorithm~\ref{Double-and-add-Coron}), the partial sums are computed as follows: $S_k(P) = \sum_{i=0}^{k}d_{n-i}2^{k-i} P=\sum_{i=0}^{k-1}d_{n-i}2^{k-1-i}(2P)+d_{n-k}P= S_{k-1}(2P)+d_{n-k}P$. So, the intermediate result of the algorithm at step $k$ when given input $P$ will be equal to the intermediate result at step $k-1$ when given input $2P$, if and only if, $d_{n-k}=0$. Therefore, an attacker can obtain the secret scalar by comparing the doubling computation at step $k+1$ for $P$ and at step $k$ for $2P$ to recover the bit $d_{n-k}.$ If both computations are identical, $d_{n-k}=0$, otherwise $d_{n-k}=1$.
In Coron's double-and-add-always algorithm (Algorithm~\ref{Double-and-add-Coron}), the partial sums are computed as follows: $S_m(P) = \sum_{i=1}^{m}k_{n-i}2^{m-i} P=\sum_{i=1}^{m-1}k_{n-i}2^{m-1-i}(2P)+k_{n-m}P= S_{m-1}(2P)+k_{n-m}P$. So, the intermediate result of the algorithm at step $m$ when given input $P$ will be equal to the intermediate result at step $m-1$ when given input $2P$, if and only if, $k_{n-m}=0$. Therefore, an attacker can obtain the secret scalar by comparing the doubling computation at step $m+1$ for $P$ and at step $m$ for $2P$ to recover the bit $k_{n-m}.$ If both computations are identical, $k_{n-m}=0$, otherwise $k_{n-m}=1$. It has been shown that with only two scalar multiplication requests chosen by the attacker, it is possible to recover all the bits of the scalar.~\footnote{The attacker collects one power trace for the computation of $kP$ and one for the computation of $k(2P)$. For each iteration $m=1,...,n$, he runs the attack as described and finds $k_{n-m}$.}
%%\vspace{-0.5cm}


\subsection{Contramedidas}

% TODO: apresentar uma contramedida de cada vez entre subseções com ataques, mostrando como ela protege contra um determinado ataque.

\begin{comment} % === CONTRAMEDIDAS ===
	a.	CM1 - Scalar Randomization (SR)
	b.	CM2 - Proj. Coord. Randomization and Re-randomization (CRR)
	c.	CM3 - Point Blinding (PB) 
	d.	CM4 – Scalar Splitting (SS)
\end{comment}

\subsubsection{Scalar Randomization (SR)}
	%	\begin{itemize}
	%\item 
	At the beginning of the scalar multiplication:
	\begin{enumerate}
		\item Randomly select $r\in_R \{0,1\}^n$, for a small $n$. $n=32$ seems to be a reasonable security/efficiency trade-off.
		\item Compute $k' \rcv k + r |E|$.
		\item Use $k'$ in place of $k$.
	\end{enumerate}
	
	%\item 
	\underline{Cost}: generate $n$ (pseudo-)random bits, $n$ iterations to the ECSM, MULs and ADDs to compute $k'$, $n$ bits of SRAM.\\
	%\item 
	
	\underline{Effectiveness}: vulnerable to Online Template Attacks (OTA) {[Batina,2014]}, among others.
	%	\end{itemize}

\subsubsection{Projective Coordinates (Re-)Randomization (CR)~\cite{Coron1999}}
\erick[inline]{Lucas: traduzir e escrever em texto corrido. Descrito para o caso de Montgomery Ladder somente com a coordenada $x$}
Original projective coordinates used in Mont Ladder: $(X:Z)$.\\
In the beginning of the ECSM, do:
\begin{enumerate}
	\item Generate random $\lambda \mathbb{F}_p \backslash \{0\}$.
	\item Do $Z_2 \rcv \lambda$ and $X_2 \rcv u \cdot \lambda$, where $u$ is the $x$-coordinate of input point $P$.
	\item Use $P'=(X_2:Z_2)$ in place of $P$.
\end{enumerate}	
\underline{Cost}: generation of $\ceil{log_2(p)}$ random bits, 1 M.\\
\underline{Effectiveness}: 
\begin{itemize}
	\item Resistant to Online Template Attacks~\cite{BatinaChmielewski2014}.
	\item Can also be applied to Edwards, twisted Edwards and Montgomery curves.
	\item Can also be used at every ECSM iteration (re-randomization).
\end{itemize}

\subsubsection{Point Blinding (PB)~\cite{Coron1999}}
\erick[inline]{Lucas: traduzir e escrever em texto corrido.}
Before the first scalar multiplication with scalar $k$:
\begin{itemize}
	\item Generate random point $R$ in the subgroup.
	\item Precompute and store $S = [k]R$.
\end{itemize}

At the beginning of each scalar multiplication:
\begin{itemize}
	\item Compute $T \rcv P + R$.
	\item Compute $Q \rcv [k] T$.
	\item Update $R$ and $S$: $R \rcv (-1)^t 2R$ and $S \rcv (-1)^t 2S$, $t \in \{0,1\}$ is randomly chosen.
	\item Return $W = Q - S$.
\end{itemize}

\noindent  \underline{Cost}: 2 ECADD, 2 ECDBL, SRAM memory for temps. Probably also writable non-volatile memory to store $R$ and $S$.\\
\noindent \underline{Effectiveness}: protects against horizontal SVA~\cite{MurdicaGuilley2012}, RPA~\cite{Goubin2003} and ZPA\cite{AkishitaTakagi2003}. Vulnerable to OTA~\cite{BatinaChmielewski2014}.

% Definitions ==========================================================
% RPA = Refined Power Analysis. Intermed. point with one of the coords zero.
% ZPA = Zero Value Point Attacks. Itermed. value (e.g., field elem), is zero
% SVA = Same Value Analysis. Generalization of ZPA when the intermediate value has a special value (not necessarily 0), that can be easily distinguished.
%==========================================================
\subsubsection{Scalar Splitting (SS)~\cite{ClavierJoye2001}}

Seja $k$ o escalar original de $n$ bits. Gere um inteiro $k_1 < k$ aleatoriamente e faça $k_2\rcv k - k_1$. Calcule $Q\rcv [k_1]P$, $T\rcv[k_2]P$ e $R\rcv Q + T$. 

\noindent \underline{Custo}: 1 ECSM de $n$ bits e 1 ECADD. Pode ser reduzido se for empregado truque de Shamir para multiplicação escalar dupla (versão regular)~\cite{CietJoye2003}.\\
\noindent \underline{Eficácia}: Resistente à TA, SPA clássico e CPA clássico.\\
\noindent \underline{Variantes}: Euclidean splitting~\cite{CietJoye2003} e multiplicative splitting~\cite{TrichinaBelleza2003}, ambas com a mesma eficácia da versão original, também conhecida como additive splitting.

\begin{comment} % === Ataques SCA contra ECC devem ser do tipo single-trace  ===
5.	Explicar porque no contexto de PKC (RSA e ECC) não fazem sentido ataques que envolvem mais de um trace, como p.ex., DPA.
\end{comment}


\begin{comment}  % === ESTRUTURA ORIGINAL ===
\subsubsection{Ataques baseados em templates}
\subsubsection{Ataques horizontais baseados em cross-correlation}
\subsubsection{Ataques horizontais não-supervisionados baseados em clustering}

\subsubsection{Aplicação de contramedidas em algoritmo esquerda para direita inseguro}
\subsubsection{Implementações de tempo constante}
\subsubsection{Implementações resistentes ao SPA}
\subsubsection{Impacto das contramedidas no desempenho}

\subsection{Eficácia de implementação de tempo constante}
\subsubsection{Outros métodos para inviabilizar ataques por tempo}
\end{comment}

\subsection{Ataque SPA à alg. Montgomery Ladder com SR}

\erick[inline]{Descrever idéia de online template attack (OTA)~\cite{BatinaChmielewski2014}}

\subsection{Ataque SPA à alg. ECSM atômico com SR}
\erick[inline]{Explicar como online template attack (OTA)~\cite{BatinaChmielewski2014} pode ser aplicado neste caso}

\subsection{Ataque template SPA à alg. Montgomery Ladder com SR + CRR}

\erick[inline]{Copy-and-paste de partes do meu paper no SAC 2016.}

\subsection{Ataques Horizontais (HA)}
% source: RSC-intern-plan

Ataques horizontais (HA) são uma metodologia para ataques por canal lateral cujos alvos são as principais operações criptográficas em protocolos baseados em RSA e ECC, a exponenciação modular e a multiplicação escalar, respectivamente. Em teoria, tais ataques permitem recuperar os bits do expoente/escalar secreto através da análise de traces individuais, isto é, apenas um único trace obtido do alvo é suficiente, portanto são eficazes contra implementações protegidas por contramedidas como SR, CR, PB e SS.

Um requisito básico dos ataques horizontais é o conhecimento do algoritmo de multiplicação escalar. De posse de tal informação, o atacante pode escolher, dentre outros, os seguintes distinguishers ou métodos \erick{verificar se distinguishers foi definido previamente ou um termo em portugues foi usado previamente}: correlation analysis, collision-correlation analysis e cluster analysis.     %SPA, distancia euclidiana, horizontal correlation analysis, horizontal collision-correlation, horizontal cross-correlation ou clustering.

% Correlation analysis
O método de correlation analysis~\cite{Clavier2010} segue o mesmo princípio da análise de potência por correlação (CPA)~\erick{usar a tradução introduzida na seção onde este assunto é tratado} aplicada a um conjunto de traces, na configuração vertical. A diferença para o contexto horizontal é de que um único trace é dividido em vários segmentos e para cada um destes segmentos um valor intermediário hipotético é atribuído, com respeito a um chute sobre o valor da chave. A correlação entre amostra e valor hipotético é calculada do mesmo modo que CPA, e os modelos de vazamentos usualmente utilizados são o peso de Hamming e a distância de Hamming. Este método funciona contra implementações protegidas somente com SR, ou quando CR é também aplicada mas o parâmetro aleatório utilizado é curto, e ataques por força bruta ao valor de tal parâmetro são viáveis.

% Collision-correlation analysis
O método de collision-correlation analysis~\cite{Bauer2013_CTRSA, Bauer2013, Clavier2012_Indocrypt, WittemanWoundenbergMenari2011, Walter2001_Ches} computa a correlação ou distância euclideana entre diferentes segmentos de um trace. O objetivo principal é identificar a ocorrência de um mesmo dado intermediário em diferentes partes de um trace, e com isso derivar os bits do escalar secreto. Para tanto, o atacante deve ter conhecimento sobre o algoritmo de ECSM empregado. Em teoria, este método é viável contra implementações envolvendo combinações de contramedidas clássicas.

% Desafios / limitações
A maioria das formas de ataques horizontais requer pré-processamento avançado dos traces, caracterização e avaliação de vazamento antes da aplicação de distinguishers. Os principais problemas da abordagem horizontal são de que extrair o vazamento a partir de um único trace tipicamente apresenta fortes limitações e desafios, como o alto nível de ruído e a indisponibilidade de amostras rotuladas. Em particular, métodos de avaliação de vazamento, como o TVLA~\cite{Goodwill2011}, requerem amostras rotuladas e isso não é possível quando a contramedida SR é aplicada.

% Cluster analysis
Métodos baseados em aprendizado não supervisionado, mais especificamente aqueles baseados em clustering, foram recentemente aplicados para resolver tais limitações e têm se mostrado capazes de produzir resultados práticos. Heyszl et al~\cite{Heyszl2013} propõem aplicar classificação por clustering à um único trace para possibilitar a identificação de classes específicas de operações; este método funciona bem para medições com baixo ruído e requer uma estação de EM composta de múltiplas sondas. Em Perin et al's~\cite{Perin2014}, os autores consideram uma abordagem heurística baseada na diferença de médias para a seleção de pontos de interesse. Além disso, ambas soluções usam um único trace como entrada para a etapa de avaliação de vazamento, o qual pode ter sido muito afetado por uma grande quantidade de ruído. Perin e Chmielewski~\cite{PerinChmielewski2015} fornecem uma metodologia para ataques horizontais baseados em clustering que foca em corrigir as deficiências dos trabalhos mencionados anteriormente.

\subsection{Ataque HCA à alg. Montgomery Ladder c/ SR + CRR}
% Meu projeto na RSC, artigos Perin 2014 e 2015.

\subsubsection{Preparação: filtragem, segmentação e alinhamento}
% filtragem dos traces
% segmentação dos traces em iterações da ECSM
% alinhamento dos subtraces

Em ataques horizontais, devido a problemas como o alto nível de ruído presente em um trace, fenômenos como clock drift ou jitter~\erick{definir} e variações no tempo em que dispositivo de medição (osciloscópio) inicia a medição após o recebimento do sinal de trigger, é fundamental o preprocessamento dos traces medidos antes de iniciar a análise, particularmente as operações de filtragem, segmentação e alinhamento.

\noindent \textbf{Filtragem.} A Figura~\erick{fig} mostra um trace não filtrado (a) e o mesmo trace após aplicação de filtro passa banda centralizado na frequência de operação do dispositivo (b), onde pode-se identificar com mais clareza características do sinal, como periodicidade e amplitude. É recomendável que filtros analógicos sejam aplicados, sempre que possível, de modo que o sinal que é digitalizado pelo osciloscópio contém apenas as frequências desejadas, permitindo o uso da menor resolução (range) vertical suportada pelo dispositivo, o que pode não ocorrer caso picos em frequências indesejadas estejam presentes.

\noindent \textbf{Segmentação.} Os traces de potência medidos tipicamente correspondem à execução completa da operação criptográfica, sendo assim são contíguos e contêm todas as rodadas (rounds) ou sub-operações executadas; no contexto da multiplicação escalar, as rodadas são as $n$ iterações do laço do algoritmo de multiplicação escalar implementado. Tais traces devem ser primeiramente segmentados em iterações, de modo que um conjunto de $n$ subtraces é obtido, cada um contendo as amostras correspondentes à respectiva iteração.

\noindent Tal segmentação pode ser realizada de diversas maneiras. Um método ingênuo é identificar os índices das amostras de início e fim da execução do laço da ECSM, e então dividir este segmento em $n$ segmentos de igual (ou quase igual) comprimento, cada qual correspondendo a uma iteração. Tal método apresenta dois problemas, o primeiro é de que em geral é difícil identificar as amostras de início e fim; o segundo é que o comprimento dos segmentos das iterações podem variar devido ao clock jitter. Um método mais robusto, que ameniza tais dificuldades, é aplicar um filtro passa baixa forte, de modo a identificar segmentos do trace que se repetem de uma iteração para outra; localizar então picos nestes segmentos cuja distância entre si é aproximadamente a mesma (Tal distância é o valor aproximado do comprimento daquela iteração) e por fim cortar o trace original utilizando tais comprimentos como referência. No entanto, devido às dificuldades anteriormente mencionadas, é provável que a segmentação obtida não seja perfeita, e portanto amostras do início de um iteração poderão estar presentes no trace da iteração anterior, bem como amostras do fim de um iteração poderão estar no início do trace da iteração seguinte e analogamente com relação à primeira e a última iterações e as partes do trace externas ao laço da ECSM.

\noindent \textbf{Alinhamento.} Dado que a segmentação provavelmente não será perfeita, uma operação aritmética realizada no intervalo de amostras $tr_i[s..e]$ no trace da iteração $i$ muito provavelmente ocorrerá em um itervalo diferente $tr_j[s'..e']$ no trace da iteração $j$. Logo, é necessário alinhar todos os subtraces de iterações da ECSM. A Figura~\erick{capturar Printscreen de um traceset no Inspector ANTES e APÓS alinhamento} mostra alguns traces resultantes da segmentação antes e após alinhamento estático por correlação. Diversos algoritmos para alinhamento de traces para SCA são propostos na literatura, dentre eles o alinhamento estático e o alinhamento elástico~\cite{WoudenbergWittemanBakker2011}. O alinhamento estático é um método simples que consiste, a grosso modo, em escolher um trace de referência e deslizar incrementalmente o trace a ser alinhado sobre o de referência e computar a distância entre eles de acordo com alguma métrica, p.ex. o coeficiente de correlação de Pearson; após deslizar por um dado número de posições, dentro de uma janela, considera-se que o trace estará alinhado se for deslocado (\textit{shifted}) até a posição cuja distância foi mínima.

\subsubsection{Algoritmos para clustering}
% Citar que K-Means, Fuzzy KMeans e Expectation-Maximization já foram empregados para este propósito, e apresentaram resultados semelhantes.

Em SCA, métodos de análise baseados em aprendizado de máquina, tais como Support Vector Machines~\cite{Bartkewitz2013}, Random forests~\cite{Lerman2014RFandSOM}, análise de séries temporais~\cite{Lerman2013} e análise nebulosa (\textit{Fuzzy analysis})~\cite{SaeediKong2014}  tem sido recentemente empregados como uma alternativa ao método de template attack no contexto de ataques~\textit{profiled}, em particular quando a distribuição das amostras difere muito da distribuição gaussiana; e também no contexto de ataques não profiled, através da utilização de algoritmos de clustering não supervisionados.

%No contexto de HCA, algoritmos de aprendizado não supervisionado baseados em clustering obtiveram sucesso em implementações \erick{continuar e citar}.

Dentre os algoritmos para clustering empregados com sucesso no contexto de ataques horizontais estão o K-Means~\cite{Forgy1965KMeans, Lloyd1982KMeans}, Fuzzy K-Means~\cite{Dunn1973FuzzyKMeans} e o Expectation-Maximization (EM)~\cite{DempsterLairdRubin1977EMAlg}. O K-Means é um algoritmo de clustering rígido, isto é, cada instância (uma amostra, no contexto de HCA) é atribuída (rotulada) a um único cluster. Fuzzy K-Means and EM, por outro lado, são algoritmos de clustering suaves (\textit{soft}), pois tem como saída uma matriz de probabilidade de associação onde à cada instância está associado o grau de vínculo desta com cada um dos clusters. Referimos o leitor aos livros sobre aprendizado de máquina~\cite{Alpaydin2014, WittenFrank2011, Han2011, Bishop2007, DudaHartStork2001} para descrições destes algoritmos e variantes.

% wONT_DO: O Explicar como o algoritmo Expectation Maximization funciona.

\subsubsection{Análise com chave conhecida}
% aplica-se clustering 1D no conjunto de amostras em um dado sample index

A análise com chave conhecida consiste em determinar os pontos de interesse, isto é, os índices de amostra, onde o vazamento é mais forte, com base no conhecimento da chave. Devido à necessidade de conhecimento do valor chave/escalar, tal análise é empregada somente na fase de teste do ataque HCA, para determinar, por exemplo, quantos traces são necessários como entrada para a avaliação de vazamento, de um dado dispositivo, de modo que os pontos de interesse obtidos por aquela correspondam aos previstos e sabidamente relevantes obtidos pela análise com chave conhecida.

Tal análise consiste em aplicar o algoritmo de clusterização no conjunto de amostras presentes em um dado índice de amostra ($m$), obtendo-se dois grupos de amostras: o primeiro grupo corresponde às amostras rotuladas com o valor b ($b\in \{0,1\}$, mas não se sabe se 0 ou 1) e o segundo grupo corresponde ao valor oposto $\bar{b}$. 

O conhecimento da chave é utilizado para determinar quantos bits tiveram o seu valor corretamente identificado no agrupamento. Como não se sabe o valor de $b$, isto é, o rótulo de cada grupo, o seguinte procedimento é adotado. Toma-se $b=0$ e conta-se o número de bits corretamente identificados ($n_c$); o valor $n - n_c$ ($n$ é o comprimento em bits do escalar) é então o número de bits corretamente identificados caso a rotulação esteja errada (isto é, o correto é $b=1$). Finalmente, considera-se $max\{n_c, n - n_c\}$ o número de bits corretamente identificados.

Este procedimento acima descrito é repetido para todos os índices de amostra, e o resultado são os pontos em que o vazamento de bits da chave é mais intenso. A ordenação destes pontos em ordem decrescente do número de bits corretamente identificados fornece os pontos de interesse.

\erick[inline]{Figura com clusterizacao obtida pelo EM e os rotulos corretos (com erros destacados, se possível.}

\subsubsection{Avaliação de vazamento} % leakage assessment
% aplica-se clustering 1D no conjunto de amostras em um dado sample index. Um grande traceset é necessário.
% a seguir é aplicada uma das funções "distinguisher": DoM, MIA, SOSD ou SOST.

Técnicas de avaliação de vazamento determinam se um dispositivo criptográfico está vazando informação por canal lateral, com base em método estatístico e um modelo de vazamento. 
Em~\cite{Meynard2011} os autores testaram informação mútua (MIA)\footnote{Mutual Information Analysis.} como um método para localizar vazamento no domínio da frequência e, consequentemente, encontrar as bandas de frequência no traces de EM do RSA em que as diferenças entre quadrados e multiplicações são maiores. O Welch $t$-test é um outro método estatístico que pode ser empregado para este fim, p.ex., em metodologias como a TVLA (cf.~\Cref{sec-tvla}). Os autores de~\cite{MatherOswaldBandenburg2013} demonstraram como empregar $t$-test e MIA para localizar vazamento no domínio do tempo.

No escopo de ataques horizontais, tais métodos são empregados sem que haja conhecimento do valor da chave secreta ou de números aleatórios gerados e/ou usados pelo dispositivo. Portanto, são aplicáveis em um cenário realista onde o adversário não tem qualquer controle (escrita ou leitura) da chave dispositivo ou outra informação secreta, em particular quando contramedidas como SR e CRR são aplicadas e não podem ser desabilitadas. Os pontos em que o vazamento é mais intenso, obtidos pela aplicação de um método para análise de vazamento, são tomados como pontos de interesse (POI). O valor das amostras em tais pontos são posteriormente utilizados na fase de ataque para recuperação da chave.

O método de análise de vazamento proposto em~\cite{PerinChmielewski2015} demonstra como múltiplos traces podem ser combinados para a avaliação de vazamento, no contexto de ataques horizontais ao RSA. Tal método é baseado em clustering e funciona mesmo se o dispositivo emprega qualquer combinação das contramedidas clássicas aplicadas à implementações da exponenciação modular: exponent blinding, message or modulus randomization.\footnote{Exponent blinding e message randomization são equivalentes às contramedidas SR e CRR para ECC, respectivamente}

\subsubsection{Avaliação de vazamento baseada em clustering}

Descrevemos nesta Subseção como o método de análise de vazamento de Perin e Chmielewski~\cite{PerinChmielewski2015} pode adaptado à uma implementação do algoritmo Montgomery Ladder para multiplicação escalar. Supomos que deseja-se identificar o valor do bit do escalar utilizado em cada iteração do laço principal deste algoritmo através de algum vazamento direto ou indireto deste valor. Sejam $n_0$ e $n_1$ o número de bits 0 e 1 em um trace. A razão $n_0/n_1$ é aproximadamente constante, tendendo a $1.0$, partindo da premissa de que o bits do escalar são gerados aleatoriamente. Devido à contramedida SR, o escalar efetivamente utilizado no laço da ECSM varia entre uma execução e outra da ECSM, e portanto difere de um trace para outro.

O método tem as seguintes premissas sobre o modelo de vazamento:
\begin{itemize}
	\item \textbf{Premissa 1}: em um trace $i$, o valor médio para o conjunto de amostras em um índice $m$ que correspondem às iterações cujo bit são 0 ou 1 são, respectivamente, $\mu_0^i + \gamma_0^i$ e $\mu_1^i + \gamma_1^i$, onde $\gamma_k^i$ é um ruído aleatório com distribuição normal, $k=0,1$.
	\item \textbf{Premissa 2}: para todos os traces $i$, as médias $\mu_0^i$ e $\mu_1^i$ são constantes.
\end{itemize}

Seja um trace $i$ e as amostras localizadas em um índice $m$ deste trace. A saída do algoritmo de clustering quando aplicado a este conjunto de amostras são dois centróides, $c_{0,m}$ e $c_{1,m}$ e dois clusters de amostras $\{g_{0,m}\}$ e $\{g_{1,m}\}$ contendo $p_{0,m}$ e $p_{1,m}$ elementos cada, respectivamente, tal que $p_{0,m} + p_{1,m}\approx n_0 + n_1$.

Temos então, para todo trace $i$ e todo índice de amostra $m$ deste trace, o seguinte conjunto de parâmetros $c_{k,i}$, $\{g_{k,m}\}$, $p_{k,m} = |\{g_{k,m}\}|$ e $\sigma^2_{k,m} = Var(\{g_{k,m}\})$, para $k = 0,1$. Este conjunto de parâmetros é utilizado como entrada para uma dentre as seguintes funções estatísticas (também conhecidas como \textit{distinguishers}): diferença de médias (DoM), soma dos quadrados das diferenças (SOSD), soma dos quadrados dos $t$-values (SOST) e MIA.

Defina o seguintes parâmetros, para $k=0,1$:

\begin{equation}	r_{k,m} = \frac{min\{p_{k,m}, n_k\} }{ max\{p_{k,m}, n_k\}}	\end{equation}
\begin{equation}	\beta_{k,m} = r_{0,m} \cdot r_{1,m}	\end{equation}

As funções distinguisher DoM, SOSD, SOST podem ser então definidas do seguinte modo\footnote{Referimos o leitor a~\cite{PerinChmielewski2015} para a definição da função MIA neste caso.}:

\begin{align*}
	\text{DoM}: l_{\text{DOM}, m} 	&= |c_{0,m} - c_{1,m}| \\
	\text{SOSD}: l_{\text{SOSD}, m} &= |c_{0,m} - c_{1,m}|^2 \\
	\text{SOST}: l_{\text{SOST}, m} &= \left( \frac{|c_{0,m} - c_{1,m}|} {\sqrt{ \frac{\sigma^2_{0,m}}{p_{0,m}} + \frac{\sigma^2_{1,m}}{p_{1,m}} }}   \right) ^ 2
\end{align*}

A função distinguisher é aplicada em cada índice de amostra $m$, para cada trace $i$. O valor resultante é somado para todos os traces e a média é calculada, isto é, $\bar{l}_{\text{D}, m} = \frac{1}{N}\sum_{i=1}^{N} l^{(i)}_{\text{D}, m}$, onde $D \in \{$ DoM,SOSD,SOST,MIA $\}$. O valor $\bar{l}_{\text{D}, m}$ é portanto o valor estimado do vazamento no índice de amostra $m$, segundo a função distinguisher $D$.

A aplicação de algoritmos de clustering fornece um estimativa para as médias $\mu_{k,m}$. Por causa do somatório usado na definição de $\bar{l}_{\text{D}, m}$ e das premissas acima, o ruído $\gamma_{k,m}$ em cada amostra $m$ é eliminado se o número de traces processados é suficientemente grande. A Figura~\erick{fig} mostra o valor estimado do vazamento em cada índice de amostra para o distinguisher SOST aplicado a traces provenientes de uma implementação do algoritmo Montgomery Ladder.

\subsubsection{Ataque para recuperação de chave}
% 1) aplica-se clustering 1D e então método estatístico para combinar os resultados em cada POI;
% Ou 2) aplica-se clustering em múltiplas dimensões.

\erick[inline]{TODO}

\subsubsection{Cálculo de confidence scores}
\erick[inline]{ao concluir seção, transformar esta subseção em um simples parágrafo}


\subsection{Ataques template versus Ataques horizontais}

\noindent \textbf{Precondições e limitações dos ataques baseados em template}: Ataques baseados em template são os mais poderosos ataques do tipo SCA, segundo a teoria da informação~\cite{ChariRaoRohatgi2003}. No entanto, ataques baseados em template só podem ser realizados quando a contramedida SR não é aplicada ou quando esta pode ser desabilitada durante a fase de criação de templates (profiling), caso contrário os templates não podem ser criados. Uma outra limitação deste tipo de ataque é de que dispositivos diferentes, mesmo que sejam do mesmo modelo, mesmo lote, etc., têm imperfeições únicas resultantes do processo de fabricação as quais resultam em diferenças no consumo de potência e radiação eletromagnética. Tais diferenças podem ser grandes o suficiente de modo que os templates gerados a partir dos traces provenientes do dispositivo de profiling não sejam bons modelos do vazamento observado no dispositivo alvo do ataque, assim reduzindo a taxa de sucesso do ataque~\cite{ElaabidGuilley2012}.


\noindent \textbf{Aplicabilidade}. Até então estes ataques só foram demonstrados em CPUs embarcadas de 8, 16 e 32 bits, devido ao alto nível de SNR (Signal-to-Noise Ratio) que pode ser obtido na medição no consumo de potência e EM nestes dispositivos. Quando o SNR é baixo, além de haver pouco vazamento de dados (data-leakage) explorável do valor da chave ou valores intermediários derivados deste, o alinhamento dos subtraces torna-se também inviável, devido a inexistência de intervalos próximos da ocorrência da operação alvo em que as amostras tem valores idênticos ou semelhantes em todos os subtraces.

